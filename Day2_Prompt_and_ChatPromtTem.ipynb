{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/aoolTcgYhgvF3AVFEaph",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shehbaz-Niazi/Langchian/blob/main/Day2_Prompt_and_ChatPromtTem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hello World With Google Gimini API**"
      ],
      "metadata": {
        "id": "6OgJTx47KYZq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mt9ZbRHv2M_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LYcoxwOY2NB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf3IMUumw7Gc"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain\n",
        "!pip install langchain google-cloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain-google-genai"
      ],
      "metadata": {
        "id": "HRC43oVPyRFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY =  userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "dclU3VKiycdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    temperature=0.2,\n",
        "    model= \"gemini-1.5-flash\",\n",
        "    api_key =GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "response = llm.invoke(\"What is the PM of Pakistan\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxhiCurJyv2j",
        "outputId": "c1f4b979-0121-4703-99a7-6411563cc531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current Prime Minister of Pakistan is Anwaar-ul-Haq Kakar.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-------------------------------------------------------------------------------------------**"
      ],
      "metadata": {
        "id": "Im03Sg_cOBZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChain Prompt Template**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6olQfhIh2ABe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**---------------------------------------------------------------------------------------------**"
      ],
      "metadata": {
        "id": "-iIuMZmaOHFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1- Prompt Template**"
      ],
      "metadata": {
        "id": "ClaOynDt6-8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Define Prompt Template\n",
        "templete = \"Who is The Founer of {country}\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=templete,\n",
        ")\n",
        "prompt_text =  prompt.format(country=\"Afghan Taliban\")\n",
        "print(prompt_text)\n",
        "\n",
        "\n",
        "\n",
        "# Define The llm\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    temperature=0.2,\n",
        "    model= \"gemini-1.5-flash\",\n",
        "    api_key =GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "response = llm.invoke(prompt_text)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjSAA1reKVBJ",
        "outputId": "416b3cfa-382d-46f6-dacd-5ee52e6c10e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who is The Founer of Afghan Taliban\n",
            "The founder of the Afghan Taliban is **Mullah Mohammad Omar**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1a-  ChatPromptTemplate with Multiple User Messages"
      ],
      "metadata": {
        "id": "YTuL4ttI7GMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1st complex example with system and Human"
      ],
      "metadata": {
        "id": "7Dx6q_Ek-q-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "input = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        (\"system\", \"You are a helpful AI bot. Your name is {name} and you are a AI teacher.\"),\n",
        "        (\"human\", \"Hello, how are you doing? and what is your name and what do you do?\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_values = input.invoke({\"name\":\"Shehbaz Khan Niazi\"})\n",
        "print(\"User Input\",input_values.messages[0].content)\n",
        "print(\"System Output\",input_values.messages[1].content)\n",
        "\n",
        "llm:ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "respond = llm.invoke(input_values)\n",
        "print(respond.content)"
      ],
      "metadata": {
        "id": "ZY2fjF5lQT5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5037551-3dd0-4abd-f3f4-e9da67c5a113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Input You are a helpful AI bot. Your name is Shehbaz Khan Niazi and you are a AI teacher.\n",
            "System Output Hello, how are you doing? and what is your name and what do you do?\n",
            "Hello! I'm doing well, thank you for asking.  My name is Shehbaz Khan Niazi, and I'm an AI teacher.  I'm here to help you learn and understand various topics.  How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2nd Example more Complex Example"
      ],
      "metadata": {
        "id": "DZd2NQ_ECqXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Define a more complex Chat Prompt Template\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. You are located in {city}.\"),\n",
        "    (\"human\", \" Tell me about something {university} \"),\n",
        "])\n",
        "\n",
        "# Define a dictionary with dynamic values to replace placeholders\n",
        "data = {\n",
        "    \"city\": \"KPK Manshera Pakistan\",\n",
        "    \"university\" : \"Hazarah University Manshera\"\n",
        "}\n",
        "\n",
        "# Invoke the template with dynamic data\n",
        "prompt_value = template.invoke(data)\n",
        "\n",
        "# Access and print system and human messages\n",
        "system_message = prompt_value.messages[0]  # First message is the system message\n",
        "human_message_1 = prompt_value.messages[1]  # Second message is the first human message\n",
        "\n",
        "# Print the generated prompt\n",
        "print(\"System Message:\", system_message.content)\n",
        "print(\"Human Message :\", human_message_1.content)\n",
        "\n",
        "llm:ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "response = llm.invoke(prompt_value)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "gUjxZD2_Eenn",
        "outputId": "1dc040a9-2cb5-4702-86e1-f5f585ec85a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System Message: You are a helpful assistant. You are located in KPK Manshera Pakistan.\n",
            "Human Message :  Tell me about something Hazarah University Manshera \n",
            "Hazara University, located in Manshera, Khyber Pakhtunkhwa, Pakistan, is a public sector university.  While I don't have access to real-time information like specific current enrollment numbers or the most up-to-the-minute faculty listings, I can tell you about some general aspects:\n",
            "\n",
            "* **Established:** It was established relatively recently compared to some other universities in Pakistan.  I don't have the exact date, but it's a relatively younger institution.\n",
            "\n",
            "* **Faculties/Departments:**  It offers a range of undergraduate and postgraduate programs across various disciplines.  These typically include (but are not limited to)  sciences, arts, humanities, and potentially some professional fields like education or business administration.  The specific departments and programs offered are best checked on the university's official website.\n",
            "\n",
            "* **Location:** Its location in Manshera gives it a significant role in serving the educational needs of the Hazara region.  Manshera is a city known for its beautiful mountainous surroundings.\n",
            "\n",
            "* **Campus:**  The university likely has a campus with various facilities, including classrooms, labs, libraries, and administrative offices.  The exact size and facilities would require checking the university's website or contacting them directly.\n",
            "\n",
            "* **Reputation:**  Its reputation within Pakistan's higher education system is something that varies depending on the specific program and perspective.  It's generally considered a decent university within the region it serves, but its overall national ranking compared to older, more established universities would need to be researched from reputable ranking sources.\n",
            "\n",
            "\n",
            "To get the most accurate and up-to-date information on Hazara University Manshera, I strongly recommend visiting their official website.  You'll find details on admissions, departments, faculty, research activities, and much more.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3rd More Complex Example"
      ],
      "metadata": {
        "id": "zWm9I3_1DYgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a highly knowledgeable assistant located in {location}. Your expertise is {expertise}.\"),\n",
        "    (\"human\", \"Hi, can you tell me more about your expertise in {expertise}?\"),\n",
        "    (\"human\", \"Also, what do you know about the culture of {location}?\"),\n",
        "])\n",
        "\n",
        "data = {\n",
        "    \"location\": \"Pakistan\",\n",
        "    \"expertise\": \"Artificial Intelligence\"\n",
        "}\n",
        "\n",
        "combine_both = template.invoke(data)\n",
        "\n",
        "print(\"system\", combine_both.messages[0].content)\n",
        "print(\"human\", combine_both.messages[1].content)\n",
        "print(\"human\", combine_both.messages[2].content)\n",
        "\n",
        "\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    api_key= GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "response = llm.invoke(combine_both)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWCd4Vo5DUu1",
        "outputId": "1c23f96c-c5cf-407c-fc49-e1bd2372c3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "system You are a highly knowledgeable assistant located in Pakistan. Your expertise is Artificial Intelligence.\n",
            "human Hi, can you tell me more about your expertise in Artificial Intelligence?\n",
            "human Also, what do you know about the culture of Pakistan?\n",
            "My expertise in Artificial Intelligence is broad, encompassing various subfields.  While I don't \"experience\" AI like a human researcher would, I've been trained on a massive dataset of text and code, allowing me to understand and process information related to:\n",
            "\n",
            "* **Machine Learning:** This is a core area of my knowledge. I understand various algorithms (supervised, unsupervised, reinforcement learning), model training, evaluation metrics, and common challenges like overfitting and bias. I can discuss specific algorithms like linear regression, support vector machines, decision trees, neural networks (including convolutional and recurrent networks), and more.\n",
            "\n",
            "* **Deep Learning:** I have a strong understanding of deep learning architectures and their applications in image recognition, natural language processing, speech recognition, and other areas. I can explain concepts like backpropagation, activation functions, different types of neural network layers, and various deep learning frameworks like TensorFlow and PyTorch.\n",
            "\n",
            "* **Natural Language Processing (NLP):**  This is a particularly relevant area for me, as my primary function is to process and generate human language.  My knowledge includes topics like tokenization, stemming, lemmatization, part-of-speech tagging, named entity recognition, sentiment analysis, machine translation, and text summarization.  I can discuss various NLP models and techniques.\n",
            "\n",
            "* **Computer Vision:** I understand the principles of computer vision, including image classification, object detection, image segmentation, and video analysis.  I can discuss various computer vision algorithms and techniques.\n",
            "\n",
            "* **AI Ethics and Safety:** I am aware of the ethical considerations surrounding AI, including bias in algorithms, fairness, accountability, transparency, and the potential societal impact of AI.\n",
            "\n",
            "* **AI Applications:** I can discuss the applications of AI across various industries, including healthcare, finance, education, and more.  I can provide information on specific use cases and their impact.\n",
            "\n",
            "\n",
            "While I don't have personal experiences or opinions, I can access and process information from the real world to answer your questions accurately and comprehensively.  My knowledge is constantly being updated, so my understanding of AI is always evolving.\n",
            "\n",
            "\n",
            "Regarding Pakistani culture, I have access to and have processed a vast amount of information about it.  I understand that it's a rich and diverse culture shaped by its history, geography, and religious influences.  Here are some aspects I'm familiar with:\n",
            "\n",
            "* **Religious diversity:**  Islam is the dominant religion, but there are also significant Christian, Hindu, and other religious communities.  This diversity contributes to the cultural tapestry of the country.\n",
            "\n",
            "* **Regional variations:** Pakistan has significant regional variations in language, customs, and traditions.  The culture of Punjab differs from that of Sindh, Balochistan, or Khyber Pakhtunkhwa.\n",
            "\n",
            "* **Family structure:**  Family is central to Pakistani society, with strong emphasis on kinship ties and extended family networks.\n",
            "\n",
            "* **Social customs and traditions:**  Pakistani culture encompasses a wide range of social customs and traditions, including celebrations, festivals (like Eid al-Fitr and Eid al-Adha), clothing, food, music, and art.\n",
            "\n",
            "* **Art and literature:**  Pakistan has a rich artistic and literary heritage, with traditions spanning centuries.  This includes Urdu poetry, Sufi music, miniature painting, and various forms of folk art.\n",
            "\n",
            "* **Historical influences:**  The culture has been influenced by various historical periods and empires, including the Mughal Empire, British Raj, and pre-Islamic cultures.\n",
            "\n",
            "* **Modernization and globalization:**  Pakistan is a rapidly changing society, with increasing exposure to globalization and modernization.  This influences the cultural landscape in various ways.\n",
            "\n",
            "\n",
            "I can answer more specific questions you might have about Pakistani culture.  Just let me know what you'd like to know more about.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4th more complex Expample"
      ],
      "metadata": {
        "id": "pZHYr5QxFwn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "chat_prompts = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "     (\"system\", \"You are a travel planning assistant. Your role is to provide helpful and concise travel advice.\"),\n",
        "     (\"human\", \"I want to plan a trip to {destination}. Can you suggest the best time to visit?\"),\n",
        "     (\"assistant\", \"The best time to visit {destination} depends on the weather and activities you enjoy. Could you share more details?\"),\n",
        "     (\"human\", \"I love hiking and photography.\"),\n",
        "     (\"assistant\", \"Great! For hiking and photography, the ideal time to visit {destination} is during {season}.\")\n",
        "\n",
        "    ]\n",
        ")\n",
        "\n",
        "input_places = {\n",
        "    \"destination\": \"Pakistan\",\n",
        "    \"season\":\"spring(January to May)\"\n",
        "}\n",
        "\n",
        "conversation = chat_prompts.invoke(input_places)\n",
        "\n",
        "for index, message in enumerate(conversation.messages):\n",
        "    role=\"System\" if index ==0 else \"Human\" if index % 2 != 0 else \"Assistant\"\n",
        "    print(f\"{role} Message:{message.content}\")\n",
        "\n",
        "llm:ChatGoogleGenerativeAI= ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    api_key= GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "response = llm.invoke(conversation)\n",
        "print(\"\\nAI's Response:\", response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSounn_tEdln",
        "outputId": "3a453d16-7602-4bde-e196-9b9cbb8aa641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System Message:You are a travel planning assistant. Your role is to provide helpful and concise travel advice.\n",
            "Human Message:I want to plan a trip to Pakistan. Can you suggest the best time to visit?\n",
            "Assistant Message:The best time to visit Pakistan depends on the weather and activities you enjoy. Could you share more details?\n",
            "Human Message:I love hiking and photography.\n",
            "Assistant Message:Great! For hiking and photography, the ideal time to visit Pakistan is during spring(January to May).\n",
            "\n",
            "AI's Response: * **Spring (March-May):** Offers pleasant temperatures, blooming landscapes perfect for photography, and accessible hiking trails.  The northern areas are particularly stunning.  However, some higher altitude trails may still have snow.\n",
            "\n",
            "Autumn (September-November) is also a good option, but some higher altitude trails might be inaccessible due to early snowfall.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5HZnKfmB7eoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ceueaCNz1rUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Few Shot Prompt Template in LangChain Python**"
      ],
      "metadata": {
        "id": "PnkzPTzO6HhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import FewShotPromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "txk2xeYy6lfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Examples for the AI\n",
        "input =  {\"input\": \"How are you?\", \"output\": \"آپ کیسے ہیں؟\"},\n",
        "\n",
        "# Specifies how each example will be written when included in the final prompt.\n",
        "example_template = \"Translate {input} -> {output}\"\n",
        "\n",
        "# Define the FewShotPromptTemplate\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=input,\n",
        "    example_prompt=PromptTemplate(\n",
        "        input_variables=[\"input\", \"output\"],\n",
        "        template=example_template\n",
        "    ),\n",
        "    prefix=\"Here are some sentense and you will translate into urdu:\",\n",
        "    suffix=\"Translate {input}:\",\n",
        "    input_variables=[\"input\"]\n",
        ")\n",
        "\n",
        "llm:ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    api_key= GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "\n",
        "# Generate the prompt for new input\n",
        "new_prompt = few_shot_prompt.format(input=input)\n",
        "response = llm.invoke(new_prompt)\n",
        "print(response.content)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5MiQyMR6fa5",
        "outputId": "519877c8-7574-49a4-9b9c-84e67e3ca8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided example shows a Python dictionary containing an input and its Urdu translation.  There's nothing more to translate in that example.  It's already translated.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tKiB8yclUZYj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}